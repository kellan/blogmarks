<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="https://laughingmeme.org/links/" />
  <id>https://laughingmeme.org/links/</id>
  <title>Kellan Elliott-McCrea&apos;s Linkblog</title>
  <subtitle>Mindless Link Propagation</subtitle>
  
  <author>
    <name>Kellan Elliott-McCrea</name>
  </author>
  
    
    <entry>
      
      <title>Voynich manuscript - an illustrated codex hand-written in an unknown script by an unknown author</title>
      <link href="https://en.wikipedia.org/wiki/Voynich_manuscript" />
      <updated>2024-06-08T19:59:57Z</updated>
      <id>https://en.wikipedia.org/wiki/Voynich_manuscript</id>
      <summary type="html">
        &lt;a href=&#34;https://en.wikipedia.org/wiki/Voynich_manuscript&#34;&gt;Voynich manuscript - an illustrated codex hand-written in an unknown script by an unknown author&lt;/a&gt; - I&#39;m going to be honest, I just learned about this using Simon&#39;s &#34;fascinate me&#34; prompt to make sure I had `llm` installed correctly.
      </summary>
      
        <category term="article" />
      
        <category term="cryptography" />
      
        <category term="history" />
      
        <category term="llm" />
      
        <category term="mlp" />
      
        <category term="wikipedia" />
      
    </entry>
  
    <entry>
      
      <title>ASML and TSMC Can Disable Chip Machines If China Invades Taiwan</title>
      <link href="https://www.bloomberg.com/news/articles/2024-05-21/asml-tsmc-can-disable-chip-machines-if-china-invades-taiwan" />
      <updated>2024-05-22T00:20:08Z</updated>
      <id>https://www.bloomberg.com/news/articles/2024-05-21/asml-tsmc-can-disable-chip-machines-if-china-invades-taiwan</id>
      <summary type="html">
        &lt;a href=&#34;https://www.bloomberg.com/news/articles/2024-05-21/asml-tsmc-can-disable-chip-machines-if-china-invades-taiwan&#34;&gt;ASML and TSMC Can Disable Chip Machines If China Invades Taiwan&lt;/a&gt; - That’s a peak 2024 headline if you ever needed one.
      </summary>
      
        <category term="china" />
      
        <category term="chips" />
      
        <category term="mlp" />
      
        <category term="taiwan" />
      
    </entry>
  
    <entry>
      
      <title>Clustering ideas with Llamafile</title>
      <link href="https://blog.lmorchard.com/2024/05/10/topic-clustering-llamafile/" />
      <updated>2024-05-13T01:32:49Z</updated>
      <id>https://blog.lmorchard.com/2024/05/10/topic-clustering-llamafile/</id>
      <summary type="html">
        &lt;a href=&#34;https://blog.lmorchard.com/2024/05/10/topic-clustering-llamafile/&#34;&gt;Clustering ideas with Llamafile&lt;/a&gt; - TL;DR: In my previous post, I used local models with PyTorch and Sentence Transformers to roughly cluster ideas by named topic. In this post, I&#39;ll try that again, but this time with Llamafile.
      </summary>
      
        <category term="ai" />
      
        <category term="llamafile" />
      
        <category term="llm" />
      
        <category term="lmorchard" />
      
        <category term="mlp" />
      
        <category term="quotable" />
      
    </entry>
  
    <entry>
      
      <title>GraphRAG (Graphs + Retrieval Augmented Generation)</title>
      <link href="https://www.microsoft.com/en-us/research/project/graphrag/" />
      <updated>2024-05-11T19:14:36Z</updated>
      <id>https://www.microsoft.com/en-us/research/project/graphrag/</id>
      <summary type="html">
        &lt;a href=&#34;https://www.microsoft.com/en-us/research/project/graphrag/&#34;&gt;GraphRAG (Graphs + Retrieval Augmented Generation)&lt;/a&gt; - RAG fails on global questions directed at an entire text corpus, such as “What are the main themes in the dataset?”, since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. ... Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely-related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user.  
      </summary>
      
        <category term="ai" />
      
        <category term="microsoft" />
      
        <category term="mlp" />
      
        <category term="paper" />
      
        <category term="python" />
      
        <category term="quotable" />
      
        <category term="rag" />
      
    </entry>
  
</feed>