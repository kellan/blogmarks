<link rel="stylesheet" href="https://laughingmeme.org/assets/main.css">
<style>
    article {
        padding: 10px;
    }

    .post-meta {
        font-size: 0.9em;
        font-style: italic;
    }

    q {
        padding-right: 23px;
        font-style: italic;
        display: inline;
    }

    div.about {
        position: relative;
    }

    div.about h1 {
        padding: 0;
        margin: 0;
    }

    div.about h2 {
        font-size: 1em;
    }

    nav.site-nav {
        position: absolute;
        bottom: 0em;
        right: 0.5em;
    }
</style>

<header class="site-header" role="banner">
    <div class="wrapper">



        <div class="about">
            <a href="https://laughingmeme.org/links/">
                <h1>Mindless Link Propagation</h1>
            </a>
            <h2>A linkblog by Kellan Elliott-McCrea</h2>

            <nav class="site-nav">
                <div class="trigger">
                    <a href="https://laughingmeme.org/about/">about</a> •
                    <a href="archive.html">archive</a> •
                    <a href="index.atom">feed</a>
                </div>
            </nav>
        </div>
</header>

<main class="page-content" aria-label="Content">
    <div class="wrapper">

        

        



<article id="link-{post.hash}">

    


    <span class="link-title">
        <a class="" href="https://en.wikipedia.org/wiki/Voynich_manuscript">
            Voynich manuscript - an illustrated codex hand-written in an unknown script by an unknown author
        </a>
    </span>
    
    <span class="dash">&mdash;</span>
    <span class="link-description">
        I&#39;m going to be honest, I just learned about this using Simon&#39;s &#34;fascinate me&#34; prompt to make sure I had `llm` installed correctly.
    </span>
    
    

    
    <span class="post-meta">
        (<span class="post-date">2024-06-08</span>

        
        &middot; <span class="tags"><a href="https://pinboard.in/u:kellan/t:article">article</a>, <a href="https://pinboard.in/u:kellan/t:cryptography">cryptography</a>, <a href="https://pinboard.in/u:kellan/t:history">history</a>, <a href="https://pinboard.in/u:kellan/t:llm">llm</a>, <a href="https://pinboard.in/u:kellan/t:mlp">mlp</a>, <a href="https://pinboard.in/u:kellan/t:wikipedia">wikipedia</a></span>
        )
    </span>
</article>

<article id="link-{post.hash}">

    


    <span class="link-title">
        <a class="" href="https://www.bloomberg.com/news/articles/2024-05-21/asml-tsmc-can-disable-chip-machines-if-china-invades-taiwan">
            ASML and TSMC Can Disable Chip Machines If China Invades Taiwan
        </a>
    </span>
    
    <span class="dash">&mdash;</span>
    <span class="link-description">
        That’s a peak 2024 headline if you ever needed one.
    </span>
    
    

    
    <span class="post-meta">
        (<span class="post-date">2024-05-22</span>

        
        &middot; <span class="tags"><a href="https://pinboard.in/u:kellan/t:china">china</a>, <a href="https://pinboard.in/u:kellan/t:chips">chips</a>, <a href="https://pinboard.in/u:kellan/t:mlp">mlp</a>, <a href="https://pinboard.in/u:kellan/t:taiwan">taiwan</a></span>
        )
    </span>
</article>

<article id="link-{post.hash}">

    
    
    <q>TL;DR: In my previous post, I used local models with PyTorch and Sentence Transformers to roughly cluster ideas by named topic. In this post, I&#39;ll try that again, but this time with Llamafile.</q>

    <span class="dash">&mdash;</span>
    
    <cite>
        <a class="" href="https://blog.lmorchard.com/2024/05/10/topic-clustering-llamafile/">
            Clustering ideas with Llamafile
        </a>
        
    </cite>
    
    <span class="post-meta">
        (<span class="post-date">2024-05-13</span>

        
        &middot; <span class="tags"><a href="https://pinboard.in/u:kellan/t:ai">ai</a>, <a href="https://pinboard.in/u:kellan/t:llamafile">llamafile</a>, <a href="https://pinboard.in/u:kellan/t:llm">llm</a>, <a href="https://pinboard.in/u:kellan/t:lmorchard">lmorchard</a>, <a href="https://pinboard.in/u:kellan/t:mlp">mlp</a>, <a href="https://pinboard.in/u:kellan/t:quotable">quotable</a></span>
        )
    </span>
</article>

<article id="link-{post.hash}">

    
    
    <q>RAG fails on global questions directed at an entire text corpus, such as “What are the main themes in the dataset?”, since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. ... Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely-related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user.  </q>

    <span class="dash">&mdash;</span>
    
    <cite>
        <a class="" href="https://www.microsoft.com/en-us/research/project/graphrag/">
            GraphRAG (Graphs + Retrieval Augmented Generation)
        </a>
        
    </cite>
    
    <span class="post-meta">
        (<span class="post-date">2024-05-11</span>

        
        &middot; <span class="tags"><a href="https://pinboard.in/u:kellan/t:ai">ai</a>, <a href="https://pinboard.in/u:kellan/t:microsoft">microsoft</a>, <a href="https://pinboard.in/u:kellan/t:mlp">mlp</a>, <a href="https://pinboard.in/u:kellan/t:paper">paper</a>, <a href="https://pinboard.in/u:kellan/t:python">python</a>, <a href="https://pinboard.in/u:kellan/t:quotable">quotable</a>, <a href="https://pinboard.in/u:kellan/t:rag">rag</a></span>
        )
    </span>
</article>


    </div>
</main>